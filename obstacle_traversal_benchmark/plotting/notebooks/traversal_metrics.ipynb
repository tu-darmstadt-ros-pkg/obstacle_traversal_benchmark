{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(data_path):\n",
    "    if os.path.isfile(data_path):\n",
    "        data = np.genfromtxt(data_path, names=True, delimiter=\",\")\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Could not open file\", data_path)\n",
    "        return None\n",
    "    \n",
    "def load_csv_files(directory, data_type, data_dict):\n",
    "    csv_files = glob.glob(os.path.join(directory, '*' + data_type + '.csv'))\n",
    "\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        label = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "        if label.startswith(\"_\"):\n",
    "            continue\n",
    "        data = load_data(csv_file)\n",
    "        label = label[:label.rfind(data_type)-1]\n",
    "        data_dict[label] = data\n",
    "\n",
    "    if len(data_dict) == 0:\n",
    "        print(\"Failed to load any data!\")\n",
    "\n",
    "def filter_nan(data_dict):\n",
    "    for label, data in data_dict.items():\n",
    "        data_clean = data[~np.isnan(data[\"stability\"])]\n",
    "        count_cleaned = len(data[\"stability\"]) - len(data_clean[\"stability\"])\n",
    "        if count_cleaned > 0:\n",
    "            print(f\"[WARNING] {label}: Removed {count_cleaned} entries with nan stability\")\n",
    "            data_dict[label] = data_clean\n",
    "    \n",
    "folders = [\n",
    "    \"\"\n",
    "    ]\n",
    "data_dict_imu = {}\n",
    "data_dict_stability = {}\n",
    "for folder in folders:\n",
    "    load_csv_files(folder, \"imu\", data_dict_imu)\n",
    "    load_csv_files(folder, \"stability\", data_dict_stability)\n",
    "filter_nan(data_dict_stability)\n",
    "print(f\"Loaded {len(data_dict_imu)} imu datasets.\")\n",
    "for label, data_imu in data_dict_imu.items():\n",
    "    print(label)\n",
    "print(f\"Loaded {len(data_dict_stability)} stability datasets.\")\n",
    "for label, data_imu in data_dict_stability.items():\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_binned_stability(travelled_distance, stability, bin_size):\n",
    "    # Define bin edges\n",
    "    min_distance = travelled_distance.min()\n",
    "    max_distance = travelled_distance.max()\n",
    "    bins = np.arange(min_distance, max_distance + bin_size, bin_size)\n",
    "    # print(bins)\n",
    "\n",
    "    # Assign each travelled_distance value to a bin\n",
    "    bin_indices = np.digitize(travelled_distance, bins)\n",
    "\n",
    "    # Calculate the average stability for each bin\n",
    "    binned_stability = np.zeros(len(bins) - 1)\n",
    "    for i in range(1, len(bins)):\n",
    "        indices = np.where(bin_indices == i)[0]\n",
    "        if indices.size > 0:\n",
    "            binned_stability[i-1] = np.mean(stability[indices])\n",
    "        else:\n",
    "            print(f\"[WARNING] Bin ({bins[i-1]},{bins[i]}) is empty\")\n",
    "\n",
    "    bin_values = bins[0:len(bins)-1] + bin_size / 2.0\n",
    "\n",
    "    # The binned_stability dictionary now contains the average stability values for each bin\n",
    "    # print(bin_values)\n",
    "    # print(binned_stability)\n",
    "    # for bin_range, avg_stability in binned_stability.items():\n",
    "    #     print(f\"Bin {bin_range}: Average Stability = {avg_stability}\")\n",
    "\n",
    "    return bin_values, binned_stability\n",
    "\n",
    "def compute_moving_average_over_distance(travelled_distance, stability, window_distance=1.0):\n",
    "    # Initialize the list to hold the running averages\n",
    "    running_averages = np.empty_like(stability)\n",
    "\n",
    "    # Compute running average with a 1m window\n",
    "    for i in range(len(travelled_distance)):\n",
    "        # Determine the start and end of the window\n",
    "        start_distance = travelled_distance[i] - window_distance / 2\n",
    "        end_distance = travelled_distance[i] + window_distance / 2\n",
    "        \n",
    "        # Find indices where distances fall within the window\n",
    "        window_indices = np.where((travelled_distance >= start_distance) & (travelled_distance <= end_distance))[0]\n",
    "        \n",
    "        # Compute the average stability for these indices\n",
    "        running_averages[i] = np.mean(stability[window_indices])\n",
    "    return running_averages\n",
    "\n",
    "def moving_average(data, size):\n",
    "    window = np.ones(int(size)) / float(size)\n",
    "    return np.convolve(data, window, 'same')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability plot\n",
    "# Raw relative probability per sample\n",
    "fig, ax = plt.subplots()\n",
    "ax.title.set_text(\"Stability\")\n",
    "for label, data in data_dict_stability.items():\n",
    "\n",
    "    # bin_size = 0.15\n",
    "    # bin_values, binned_stability = compute_binned_stability(data[\"travelled_distance\"], data[\"stability\"], bin_size)\n",
    "    # ax.bar(bin_values, binned_stability, width=bin_size)\n",
    "\n",
    "\n",
    "    # ax.plot(data[\"travelled_distance\"], data[\"stability\"], label=label)\n",
    "    \n",
    "    # smoothed_stability = compute_moving_average_over_distance(data[\"travelled_distance\"], data[\"stability\"], window_distance=0.25)\n",
    "    # ax.plot(data[\"travelled_distance\"], smoothed_stability, label=label + \"-smooth\")\n",
    "    ax.plot(data[\"travelled_distance\"], data[\"stability\"], label=label)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(array, label: str):\n",
    "    avg = np.mean(array)\n",
    "    sum = np.sum(array)\n",
    "    maximum = np.max(array)\n",
    "    percentile = np.percentile(array, 99)\n",
    "    # print(f\" -- Avg. {label}: {avg:.2f}, Acc. {label}: {sum:.2f}, Max. {label}: {maximum:.2f}, Perc. {label}: {percentile:.2f}\") \n",
    "    return avg, sum, maximum, percentile\n",
    "\n",
    "def compute_integral(time, data):\n",
    "    return np.trapz(data, time)\n",
    "\n",
    "def compute_smoothness_metric(x, y, z, calibration, min, max):\n",
    "    vec = np.stack((x, y, z), axis=0)\n",
    "    norm = np.linalg.norm(vec, axis=0) - calibration\n",
    "    norm = np.maximum(norm, min)\n",
    "    norm = np.minimum(norm, max)\n",
    "    return norm*norm \n",
    "\n",
    "def compute_shock(acc_x, acc_y, acc_z):\n",
    "    calibration = 10.0 # only consider hard hits\n",
    "    gravity = 9.81\n",
    "    return compute_smoothness_metric(acc_x, acc_y, acc_z, calibration + gravity, 0, 50.0)\n",
    "\n",
    "def compute_swing(vel_x, vel_y):\n",
    "    calibration = 0.5 # only consider fast swings\n",
    "    return compute_smoothness_metric(vel_x, vel_y, np.zeros_like(vel_x), calibration, 0, 3.0)\n",
    "\n",
    "# Compute trial metrics\n",
    "def compute_metrics(data_imu, data_stability):\n",
    "    # time\n",
    "    duration = max(data_imu[\"time\"][-1], data_stability[\"time\"][-1])\n",
    "    # print(f\" -- Duration: {duration:.2f}s\")\n",
    "\n",
    "    # Average stability\n",
    "    avg_stability = np.mean(data_stability[\"stability\"])\n",
    "    # _, binned_stability = compute_binned_stability(data_stability[\"travelled_distance\"], data_stability[\"stability\"], 0.12)\n",
    "    # avg_binned_stability = np.mean(binned_stability)\n",
    "    # smoothed_stability = compute_moving_average_over_distance(data_stability[\"travelled_distance\"], data_stability[\"stability\"], window_distance=1.0)\n",
    "    # smoothed_stability = moving_average(data_stability[\"stability\"], size=5)\n",
    "    # avg_smoothed_stability = np.mean(smoothed_stability)\n",
    "    # print(f\" -- Avg. stability: {avg_stability:.2f}, avg. binned stability: {avg_binned_stability:.2f}, avg. smoothed stability: {avg_smoothed_stability:.2f}\")\n",
    "\n",
    "    # Locomotion roughness\n",
    "    shock = compute_shock(data_imu[\"linear_acceleration_x\"], data_imu[\"linear_acceleration_y\"], data_imu[\"linear_acceleration_z\"])\n",
    "    # avg_shock, sum_shock, max_shock, percentile_shock = compute_statistics(shock, \"shock\")\n",
    "    int_shock = compute_integral(data_imu[\"time\"], shock)\n",
    "\n",
    "    swing = compute_swing(data_imu[\"angular_velocity_x\"], data_imu[\"angular_velocity_y\"])\n",
    "    # avg_swing, sum_swing, max_swing, percentile_swing = compute_statistics(swing, \"swing\")\n",
    "    int_swing = compute_integral(data_imu[\"time\"], swing)\n",
    "\n",
    "    return duration, avg_stability, int_shock, int_swing\n",
    "\n",
    "def print_results(result_data):\n",
    "    for label, trials in result_data.items():\n",
    "        print(\"Mode:\", label)\n",
    "        print(\"Duration Stability Shock Swing\")\n",
    "        for i, trial in enumerate(trials):\n",
    "            metrics_str = ', '.join(str(np.around(num, decimals=2)) for num in trial)\n",
    "            print(metrics_str)\n",
    "        trials_matrix = np.array(trials)\n",
    "        avg = np.mean(trials_matrix, axis=0)\n",
    "        print(f\"Avg:     {', '.join(str(np.around(num, decimals=2)) for num in avg)}\")\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "result_data = dict()\n",
    "for label, data_imu in data_dict_imu.items():\n",
    "    # print(f\"Trial {label} metrics:\")\n",
    "    data_stability = data_dict_stability[label]\n",
    "    metrics = compute_metrics(data_imu, data_stability)\n",
    "    mode = label[:label.rfind(\"trial\") -1]\n",
    "    if mode in result_data:\n",
    "        result_data[mode].append(metrics)\n",
    "    else:\n",
    "        result_data[mode] = []\n",
    "        result_data[mode].append(metrics)\n",
    "\n",
    "print_results(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "axs[0].title.set_text(\"Shock\")\n",
    "axs[1].title.set_text(\"Swing\")\n",
    "for label, data in data_dict_imu.items():\n",
    "    shock = compute_shock(data[\"linear_acceleration_x\"], data[\"linear_acceleration_y\"], data[\"linear_acceleration_z\"])\n",
    "    axs[0].plot(data[\"time\"], shock, label=label)\n",
    "\n",
    "    swing = compute_swing(data[\"angular_velocity_x\"], data[\"angular_velocity_y\"])\n",
    "    swing = np.maximum(swing, 0.0)\n",
    "\n",
    "    axs[1].plot(data[\"time\"], swing, label=label)\n",
    "    # axs[1].plot(data[\"time\"], data[\"angular_velocity_z\"])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per mode: scatter plot of shock/swing over time\n",
    "\n",
    "# Collect data per mode\n",
    "modes = [\"autonomy\", \"teleop\", \"wb_assistance\",]\n",
    "mode_labels = {\n",
    "    \"autonomy\": \"Supervised Autonomy\",\n",
    "    \"teleop\": \"Guided + Assisted Teleoperation\",\n",
    "    \"wb_assistance\": \"Shared Autonomy\",\n",
    "}\n",
    "mode_results_dict = dict()\n",
    "for label, trials in result_data.items():\n",
    "    trials_matrix = np.array(trials)\n",
    "    for mode in modes:\n",
    "        if mode in label:\n",
    "            if mode in mode_results_dict:\n",
    "                stacked = np.concatenate((mode_results_dict[mode], trials_matrix), axis=0)\n",
    "                mode_results_dict[mode] = stacked\n",
    "            else:\n",
    "                mode_results_dict[mode] = trials_matrix\n",
    "# print(mode_results_dict[\"wb_assistance\"][:, 0].min(), mode_results_dict[\"wb_assistance\"][:, 0].max())\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "bins = np.array([150, 200, 250, 300, 350])\n",
    "# bins = np.arange(150, 400, 60)\n",
    "# bins = np.array([mode_results_dict[\"wb_assistance\"][:, 0].min(), mode_results_dict[\"wb_assistance\"][:, 0].max()])\n",
    "# bins = np.arange(0, 500, 25)\n",
    "print(\"Bins\", bins)\n",
    "for i, (mode, results) in enumerate(mode_results_dict.items()):\n",
    "    axs[0].set_title(\"Shock\")\n",
    "    axs[0].scatter(results[:, 0], results[:, 2], label=mode_labels[mode])\n",
    "    axs[0].set_ylabel(\"Shock\")\n",
    "\n",
    "    axs[1].set_title(\"Swing\")\n",
    "    axs[1].scatter(results[:, 0], results[:, 2], label=mode_labels[mode])\n",
    "    axs[1].set_ylabel(\"Swing\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_histogram(ax, duration, metric, bins, bar_index, total_bars, label):\n",
    "    indices = np.digitize(duration, bins) - 1  # Find which bin each time value falls into\n",
    "    n_bins = len(bins) -1\n",
    "    # Compute average shock values for each bin\n",
    "    avg_shocks = np.array([metric[indices == i].mean() if len(metric[indices == i]) > 0 else 0 for i in range(n_bins)])\n",
    "    std_dev = np.array([metric[indices == i].std() if len(metric[indices == i]) > 0 else 0 for i in range(n_bins)])\n",
    "\n",
    "    # Plot\n",
    "    x = np.arange(n_bins)\n",
    "    default_bar_width = 1.0\n",
    "    bar_width = default_bar_width / total_bars\n",
    "    ax.bar(x + bar_index * bar_width, avg_shocks, width=bar_width, yerr=std_dev, edgecolor='black', align='edge', label=label)\n",
    "\n",
    "    ax.set_xticks(x , labels=[f\"{bins[i]:.2f}\" for i in range(n_bins)])\n",
    "    ax.set_xlabel('Duration (s)')\n",
    "    ax.set_xlim(0, n_bins)\n",
    "    # ax.set_ylim(0, avg_shocks.max() * 1.5)\n",
    "    # ax.set_title('Average Shock per Time Bin')\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig2, axs2 = plt.subplots(1, 2, figsize=(10, 4))\n",
    "fig2.tight_layout()\n",
    "bins = np.array([150, 200, 250, 300, 350])\n",
    "# bins = np.arange(150, 400, 60)\n",
    "# bins = np.array([mode_results_dict[\"wb_assistance\"][:, 0].min(), mode_results_dict[\"wb_assistance\"][:, 0].max()])\n",
    "# bins = np.arange(0, 500, 25)\n",
    "print(\"Bins\", bins)\n",
    "for i, mode in enumerate(modes):\n",
    "    results = mode_results_dict[mode]\n",
    "    axs2[0].set_title(\"Shock\")\n",
    "    plot_avg_histogram(axs2[0], results[:, 0], results[:, 2], bins, i, len(mode_results_dict), label=mode_labels[mode])\n",
    "    axs2[0].set_ylabel(\"Shock\")\n",
    "\n",
    "    axs2[1].set_title(\"Swing\")\n",
    "    plot_avg_histogram(axs2[1], results[:, 0], results[:, 3], bins, i, len(mode_results_dict), label=mode_labels[mode])\n",
    "    axs2[1].set_ylabel(\"Swing\")\n",
    "\n",
    "for ax in axs2:\n",
    "    ax.legend()\n",
    "\n",
    "plt.savefig(\"export/locomotion_smoothness_over_time\", dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with average time over trials per mode\n",
    "# x-axis: trial #\n",
    "# y-axis: avg duration per trial #\n",
    "# 4 lines + scatter for each mode\n",
    "\n",
    "# collect data\n",
    "modes = [\"autonomy\", \"guided_teleop\", \"teleop\", \"wb_assistance\",]\n",
    "mode_labels = {\n",
    "    \"autonomy\": \"Supervised Autonomy\",\n",
    "    \"teleop\": \"Assisted Teleoperation\",\n",
    "    \"guided_teleop\": \"Guided Teleoperation\",\n",
    "    \"wb_assistance\": \"Shared Autonomy\",\n",
    "}\n",
    "trail_comp_dict = dict()\n",
    "for label, trials in result_data.items():\n",
    "    trials_matrix = np.array(trials)\n",
    "    for mode in modes:\n",
    "        if mode in label:\n",
    "            trial_durations = trials_matrix[:, 0:1]\n",
    "            if mode in trail_comp_dict:\n",
    "                concat = np.concatenate((trail_comp_dict[mode], trial_durations), axis=1)\n",
    "                trail_comp_dict[mode] = concat\n",
    "            else:\n",
    "                trail_comp_dict[mode] = trial_durations\n",
    "            break\n",
    "\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.tight_layout()\n",
    "markers = [\"o\", \"x\", \"D\", \"s\"]\n",
    "max_trials = 0\n",
    "for _, results in trail_comp_dict.items():\n",
    "    trials_num = results.shape[0]\n",
    "    if trials_num > max_trials:\n",
    "        max_trials = trials_num\n",
    "x = np.arange(1, max_trials + 1, 1)\n",
    "for i, ((mode, results), marker) in enumerate(zip(trail_comp_dict.items(), markers)):\n",
    "    if results.shape[1] > 1:\n",
    "        y = np.mean(results, axis=1)\n",
    "        y_err = np.std(results, axis=1)\n",
    "    else:\n",
    "        y = results.transpose()[0]\n",
    "        y_err = np.zeros_like(y)\n",
    "    offset = 0.04\n",
    "    x_offset = x + offset * (i - len(modes) / 2.0)\n",
    "    ax.errorbar(x_offset, y, yerr=y_err, label=mode_labels[mode], fmt='--'+marker, ecolor=\"black\")\n",
    "\n",
    "ax.legend()\n",
    "# ax.set_title(\"\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xlabel(\"Trial #\")\n",
    "ax.set_ylabel(\"Avg. Duration (s)\")\n",
    "# ax.set_ylim(140, 500)\n",
    "plt.savefig(\"export/trial_comparison\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operator experience comparison\n",
    "# plot x-axis: modes, 1 bar per operator per mode\n",
    "# y-axis duration\n",
    "\n",
    "# collect data\n",
    "modes = [\"teleop\", \"wb_assistance\",]\n",
    "mode_labels = {\n",
    "    \"autonomy\": \"Supervised Autonomy\",\n",
    "    \"teleop\": \"Assisted + Guided Teleoperation\",\n",
    "    \"guided_teleop\": \"Guided Teleoperation\",\n",
    "    \"wb_assistance\": \"Shared Autonomy\",\n",
    "}\n",
    "\n",
    "operator_experience = [\"beginner\", \"intermediate\", \"expert\"]\n",
    "operator_experience_labels = {\n",
    "    \"beginner\": \"Beginner\",\n",
    "    \"intermediate\": \"Intermediate\",\n",
    "    \"expert\": \"Expert\",\n",
    "}\n",
    "\n",
    "operator_comp_dict = dict()\n",
    "for exp in operator_experience:\n",
    "    operator_comp_dict[exp] = np.zeros((3, len(modes)))\n",
    "\n",
    "for label, trials in result_data.items():\n",
    "    trials_matrix = np.array(trials)\n",
    "    for exp in operator_experience:\n",
    "        if exp in label:\n",
    "            trial_durations = trials_matrix[:, 0:1]\n",
    "            # find mode index\n",
    "            for i, mode in enumerate(modes):\n",
    "                if mode in label:\n",
    "                    mode_index = i\n",
    "                    break\n",
    "                if i == len(modes) - 1:\n",
    "                    print(\"[WARN] Could not find mode in\", label)\n",
    "\n",
    "            operator_comp_dict[exp][:, mode_index:mode_index+1] = trial_durations[:]\n",
    "            break\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.tight_layout()\n",
    "\n",
    "x = np.arange(0, len(modes), 1)\n",
    "default_bar_width = 0.8\n",
    "bar_width = default_bar_width / len(operator_experience)\n",
    "for i, (op_exp, results) in enumerate(operator_comp_dict.items()):\n",
    "    y = np.mean(results, axis=0)\n",
    "    # print(op_exp, y)\n",
    "    y_err = np.std(results, axis=0)\n",
    "    x_offset = x + (i - len(operator_experience) / 2.0) * bar_width\n",
    "    ax.bar(x_offset, y, width=bar_width, yerr=y_err, edgecolor='black', align='edge', label=operator_experience_labels[op_exp])\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xticks(x , labels=[mode_labels[modes[i]] for i in range(len(modes))])\n",
    "ax.set_ylabel(\"Avg. Duration (s)\")\n",
    "\n",
    "plt.savefig(\"export/operator_comparison\", dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_to_absolute_time(time_array, reference_time_str):\n",
    "    reference_stamp = datetime.datetime.strptime(reference_time_str, '%Y-%m-%d-%H:%M:%S.%f').replace(tzinfo=datetime.timezone.utc)\n",
    "    absolute_stamps = np.array([reference_stamp + datetime.timedelta(seconds=int(s)) for s in time_array])\n",
    "    return absolute_stamps\n",
    "\n",
    "def absolute_to_relative_time(time_array, reference_datetime):\n",
    "    relative_stamps = np.array([(absolute_time - reference_datetime).total_seconds() for absolute_time in time_array])\n",
    "    return relative_stamps\n",
    "\n",
    "def filter_data(time_stamps, data, start_time, end_time):\n",
    "    filter_indices_start = time_stamps >= start_time\n",
    "    filtered_time = time_stamps[filter_indices_start]\n",
    "    filtered_data = [d[filter_indices_start] for d in data]\n",
    "\n",
    "    filter_indices_end = filtered_time < end_time\n",
    "    filtered_time = filtered_time[filter_indices_end]\n",
    "    filtered_data = [d[filter_indices_end] for d in filtered_data]\n",
    "\n",
    "\n",
    "    return filtered_time, filtered_data\n",
    "\n",
    "\n",
    "# Plan vs execution comparison plot\n",
    "data_stability_plan = load_data(\"\")\n",
    "plan_stamp_str = \"2024-03-22-16:01:50.233347\"\n",
    "plan_stamps = relative_to_absolute_time(data_stability_plan[\"time\"], plan_stamp_str)\n",
    "plan_stamps = plan_stamps[1:]  # remove first invalid element\n",
    "plan_stability = data_stability_plan[\"stability\"][1:]\n",
    "plan_robot_x = data_stability_plan[\"result_position_x\"][1:]\n",
    "\n",
    "data_stability_measured = data_dict_stability[\"autonomy_2024-03-22-16-58-16_trial-0\"]\n",
    "trial_stamp_str = \"2024-03-22-16:01:06.552530\"\n",
    "trial_stamps = relative_to_absolute_time(data_stability_measured[\"time\"], trial_stamp_str)\n",
    "trial_stability = data_stability_measured[\"stability\"]\n",
    "trial_robot_x = data_stability_measured[\"robot_pose_position_x\"]\n",
    "\n",
    "# Smooth data\n",
    "plan_stability = moving_average(plan_stability, 1)\n",
    "trial_stability = moving_average(trial_stability, 5)\n",
    "\n",
    "# Cut data to overlapping duration\n",
    "start_time = plan_stamps[0] if plan_stamps[0] >= trial_stamps[0] else trial_stamps[0]\n",
    "end_time = plan_stamps[-1] if plan_stamps[-1] < trial_stamps[-1] else trial_stamps[-1]\n",
    "\n",
    "plan_stamps, [plan_stability, plan_robot_x] = filter_data(plan_stamps, [plan_stability, plan_robot_x], start_time, end_time)\n",
    "trial_stamps, [trial_stability, trial_robot_x] = filter_data(trial_stamps, [trial_stability, trial_robot_x], start_time, end_time)\n",
    "\n",
    "# Convert to relative start time\n",
    "plan_stamps = absolute_to_relative_time(plan_stamps, start_time)\n",
    "trial_stamps = absolute_to_relative_time(trial_stamps, start_time)\n",
    "\n",
    "# print(\"Plan points/second:\", len(plan_stamps)/plan_stamps[-1])\n",
    "# print(\"Trial points/second:\", len(trial_stamps)/trial_stamps[-1])\n",
    "\n",
    "\n",
    "# Stability plot\n",
    "fig, ax = plt.subplots(1, 1, dpi=200, figsize=(10, 5))\n",
    "fig.tight_layout()\n",
    "\n",
    "# axs[0].plot(plan_stamps, plan_stability, label=\"Plan\")\n",
    "# axs[0].plot(trial_stamps, trial_stability, label=\"Measured\")\n",
    "# axs[0].set_xlabel(\"Time (s)\")\n",
    "\n",
    "ax.plot(plan_robot_x, plan_stability, label=\"Plan\", linestyle=\"dotted\")\n",
    "ax.plot(trial_robot_x, trial_stability, label=\"Estimation\")\n",
    "# axs[1].plot(trial_robot_x, trial_stability_smooth, label=\"Measured-smooth\")\n",
    "\n",
    "ax.set_xlabel(\"Position (m)\")\n",
    "ax.set_ylabel(\"Stability Margin (FASM)\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 4)\n",
    "ax.set_xticks(np.arange(-0.5, 5, 0.5))\n",
    "\n",
    "plt.savefig(\"export/plan_comparison_stability\", dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
